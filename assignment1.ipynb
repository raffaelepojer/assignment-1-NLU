{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54814027-a981-4fcc-b795-6fe980270916",
   "metadata": {},
   "source": [
    "## Assignment: Working with Dependency Graphs (Parses)\n",
    "\n",
    "The objective of the assignment is to learn how to work with dependency graphs by defining functions.\n",
    "\n",
    "Read [spaCy documentation on dependency parser](https://spacy.io/api/dependencyparser) to learn provided methods.\n",
    "\n",
    "Define functions to:\n",
    "\n",
    "- extract a path of dependency relations from the ROOT to a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token the path will be a list of dependency relations, where first element is ROOT\n",
    "- extract subtree of a dependents given a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token in Doc objects you extract a subtree of its dependents as a list (ordered w.r.t. sentence order)\n",
    "- check if a given list of tokens (segment of a sentence) forms a subtree\n",
    "    - you parse a sentence and get a Doc object of spaCy\n",
    "    - providing as an input ordered list of words from a sentence, you output True/False based on the sequence forming a subtree or not\n",
    "- identify head of a span, given its tokens\n",
    "    - input is a sequence of words (not necessarily a sentence)\n",
    "    - output is the head of the span (single word)\n",
    "- extract sentence subject, direct object and indirect object spans\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - output is lists of words that form a span (not a single word) for subject, direct object, and indirect object (if present of course, otherwise empty)\n",
    "        - dict of lists, is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302ca55c-efb5-4cba-a5a1-cd1e3f772abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"700aaa273e6a4947881cded94e5e7995-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">saw</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">man.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-700aaa273e6a4947881cded94e5e7995-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-700aaa273e6a4947881cded94e5e7995-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-700aaa273e6a4947881cded94e5e7995-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-700aaa273e6a4947881cded94e5e7995-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-700aaa273e6a4947881cded94e5e7995-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-700aaa273e6a4947881cded94e5e7995-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# sentence = \"The objective of the assignment is to learn how to work with dependency graphs by defining functions.\"\n",
    "# sentence = \"Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.\"\n",
    "# sentence = \"bright red apples on the tree\"\n",
    "# sentence = \"Autonomous cars shift insurance liability toward manufacturers\"\n",
    "# sentence = \"The teacher gave the class some homework.\"\n",
    "# sentence = \"Sue passed Ann the ball.\"\n",
    "sentence = \"I saw the man.\"\n",
    "\n",
    "#display the dep graph\n",
    "doc1 = spacy_nlp(sentence)\n",
    "spacy.displacy.render(doc1, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541075b8-7659-41c7-b569-d7967ea50a80",
   "metadata": {},
   "source": [
    "## First point\n",
    "\n",
    "- extract a path of dependency relations from the ROOT to a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token the path will be a list of dependency relations, where first element is ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65071087-69f1-4128-b819-5bf7f448080f",
   "metadata": {},
   "source": [
    "In this point my idea was to split the problem in two function:\n",
    "- the first function __pathDep(token)__ return the path from the root to the token as a normal graph visiting. The __input__ is a *spaCy token* and the __output__ is a *list* with inside the touple *(dependecy_of_the_node, text_of_the_node)*\n",
    "- the second function __printPathDep(sent)__ print all the paths of all the tokens inside the sentence. As __input__ a *string* representing the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224f4007-36e9-41e7-80eb-944bf09307dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ROOT', 'saw'), ('nsubj', 'I')]\n",
      "[('ROOT', 'saw')]\n",
      "[('ROOT', 'saw'), ('dobj', 'man'), ('det', 'the')]\n",
      "[('ROOT', 'saw'), ('dobj', 'man')]\n",
      "[('ROOT', 'saw'), ('punct', '.')]\n"
     ]
    }
   ],
   "source": [
    "# visit as a normal graph visiting\n",
    "def pathDep(token):\n",
    "    S = []\n",
    "    path = []\n",
    "    S.append(token)\n",
    "    while len(S) > 0:\n",
    "        node = S.pop(0)\n",
    "        path.append((node.dep_, node.text))\n",
    "        if node.dep_ != \"ROOT\":\n",
    "            S.append(node.head)\n",
    "    return list(reversed(path))\n",
    "\n",
    "def printPathDep(sent):\n",
    "    doc = spacy_nlp(sent)\n",
    "    path = []\n",
    "    for token in doc:\n",
    "        path = pathDep(token)\n",
    "        print(path)\n",
    "\n",
    "printPathDep(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb74d64-d902-4c2a-8b70-e652f0890bf6",
   "metadata": {},
   "source": [
    "## Second point\n",
    "\n",
    "- extract subtree of a dependents given a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token in Doc objects you extract a subtree of its dependents as a list (ordered w.r.t. sentence order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cc6f1-ba9b-4d4d-8f1e-ac8b0952c5a2",
   "metadata": {},
   "source": [
    "Also in this point I decided to split the problem in two function, so that they can be used in the other points:\n",
    "- the first function __subTreeDep(token)__ wants a sapCy token as input an return the list representing the subtree of the token (iterating over the token.subtree)\n",
    "- the sencond function __printSubTreeDep(sent)__ recieve as input a sentence and print all the subtree of the tokens inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbcc3a4-b3f7-402f-9ba6-ed42be851b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I]\n",
      "[I, saw, the, man, .]\n",
      "[the]\n",
      "[the, man]\n",
      "[.]\n"
     ]
    }
   ],
   "source": [
    "def subTreeDep(token):\n",
    "    tree = []\n",
    "    for sub in token.subtree:\n",
    "        tree.append(sub)\n",
    "    return tree\n",
    "\n",
    "def printSubTreeDep(sent):\n",
    "    doc = spacy_nlp(sent)\n",
    "    for token in doc:\n",
    "        path = subTreeDep(token)\n",
    "        print(path)\n",
    "\n",
    "printSubTreeDep(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f953901-c887-40ab-94fa-a6f101bbf61d",
   "metadata": {},
   "source": [
    "## Third point\n",
    "\n",
    "- check if a given list of tokens (segment of a sentence) forms a subtree\n",
    "    - you parse a sentence and get a Doc object of spaCy\n",
    "    - providing as an input ordered list of words from a sentence, you output True/False based on the sequence forming a subtree or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c87d09-c3d6-4db2-af1e-83b4a4117b32",
   "metadata": {},
   "source": [
    "In the third point the function __chekSubTree(sent, tokenList)__ get as input the *string* of the sentence to parse, and the *list* of tokens to check if they are contained in a subtree of the sentence. This function reuse *subTreeDep* to retreive the subtree of each token to then compare it with the passed token list. It returns a *Boolean* as __output__.\n",
    "\n",
    "For testing I create a list of word from a sentence and then convert it in a sorted list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809892f6-4e0e-4323-8b41-32f675cec707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-create a list of word from a sentence\n",
    "tmp = \"61 years old\"\n",
    "tokens = spacy_nlp(tmp)\n",
    "listTokens = []\n",
    "for t in tokens:\n",
    "    listTokens.append(str(t))\n",
    "listTokens.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea36449-9476-41c1-b968-0768c8108ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if forms a subtree: False\n"
     ]
    }
   ],
   "source": [
    "def checkSubTree(sent, tokenlist):\n",
    "    doc = spacy_nlp(sent)\n",
    "    for token in doc:\n",
    "        path = subTreeDep(token)\n",
    "        pathString = sorted([str(t) for t in path])\n",
    "        if pathString == tokenlist:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print(\"Check if forms a subtree: {}\".format(checkSubTree(sentence, listTokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38adce5-f781-4a40-a3ca-6e655fc30063",
   "metadata": {},
   "source": [
    "## Fourth point\n",
    "\n",
    "- identify head of a span, given its tokens\n",
    "    - input is a sequence of words (not necessarily a sentence)\n",
    "    - output is the head of the span (single word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bf6b0-c6b2-44b9-a649-68914be00265",
   "metadata": {},
   "source": [
    "Here my doubts was if the input of the function can be a normal *string* or a sliced spaCy document, for this reason I develop:\n",
    "\n",
    "- __headSpan(span)__ recieve as __input__ a slice of a spaCy document and return the root\n",
    "\n",
    "- __headSpanString(span)__ recieve as __input__ a string of list of word and then convert it do a spaCy document for the computing of the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009b3347-a8f9-4627-9365-41a39164a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span: insurance liability toward\n",
      "Head of span: liability\n"
     ]
    }
   ],
   "source": [
    "doc = spacy_nlp(\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "def headSpan(span):\n",
    "    return span.root.text\n",
    "\n",
    "span = doc[3:6]\n",
    "print(\"Span: {}\".format(span))\n",
    "print(\"Head of span: {}\".format(headSpan(span)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6b5e00-e952-4760-8053-7698b551a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of span: liability\n"
     ]
    }
   ],
   "source": [
    "def headSpanString(span):\n",
    "    doc = spacy_nlp(span)\n",
    "    return doc[0:len(doc)].root.text\n",
    "\n",
    "print(\"Head of span: {}\".format(headSpanString(\"insurance liability toward\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed8952-36f7-44b0-9387-e29657d9ae8d",
   "metadata": {},
   "source": [
    "## Fifth point\n",
    "\n",
    "- extract sentence subject, direct object and indirect object spans\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - output is lists of words that form a span (not a single word) for subject, direct object, and indirect object (if present of course, otherwise empty)\n",
    "        - dict of lists, is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd3ff8-50c0-4ba4-abe0-28076d6fac05",
   "metadata": {},
   "source": [
    "This function __extractDep(sent)__ recieve in input a *string* of the sentece, convert it as a spaCy doc and returns a *dictionary* containg all the span for the *subject*, *indirect object* and *direct object* by iterating in its subtree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75571289-be44-42e6-a53e-70d2f5e3b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nsubj': [I], 'iobj': [], 'dobj': [the, man]}\n"
     ]
    }
   ],
   "source": [
    "def extractDep(sent):\n",
    "    doc = spacy_nlp(sent)\n",
    "    dic = {}\n",
    "    dic[\"nsubj\"] = []\n",
    "    dic[\"iobj\"] = []\n",
    "    dic[\"dobj\"] = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.dep_ == \"nsubj\":\n",
    "            for d in token.subtree:\n",
    "                    dic[\"nsubj\"].append(d)\n",
    "        if token.dep_ == \"dative\":\n",
    "            for d in token.subtree:\n",
    "                    dic[\"iobj\"].append(d)\n",
    "        if token.dep_ == \"dobj\":\n",
    "            for d in token.subtree:\n",
    "                    dic[\"dobj\"].append(d)\n",
    "    return dic\n",
    "\n",
    "print(extractDep(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "native39",
   "language": "python",
   "name": "native39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
