{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54814027-a981-4fcc-b795-6fe980270916",
   "metadata": {},
   "source": [
    "## Assignment: Working with Dependency Graphs (Parses)\n",
    "\n",
    "The objective of the assignment is to learn how to work with dependency graphs by defining functions.\n",
    "\n",
    "Read [spaCy documentation on dependency parser](https://spacy.io/api/dependencyparser) to learn provided methods.\n",
    "\n",
    "Define functions to:\n",
    "\n",
    "- extract a path of dependency relations from the ROOT to a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token the path will be a list of dependency relations, where first element is ROOT\n",
    "- extract subtree of a dependents given a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token in Doc objects you extract a subtree of its dependents as a list (ordered w.r.t. sentence order)\n",
    "- check if a given list of tokens (segment of a sentence) forms a subtree\n",
    "    - you parse a sentence and get a Doc object of spaCy\n",
    "    - providing as an input ordered list of words from a sentence, you output True/False based on the sequence forming a subtree or not\n",
    "- identify head of a span, given its tokens\n",
    "    - input is a sequence of words (not necessarily a sentence)\n",
    "    - output is the head of the span (single word)\n",
    "- extract sentence subject, direct object and indirect object spans\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - output is lists of words that form a span (not a single word) for subject, direct object, and indirect object (if present of course, otherwise empty)\n",
    "        - dict of lists, is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302ca55c-efb5-4cba-a5a1-cd1e3f772abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a538c2607b3e458d891ece00e98b3f74-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Sue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">passed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Ann</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">ball.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a538c2607b3e458d891ece00e98b3f74-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a538c2607b3e458d891ece00e98b3f74-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a538c2607b3e458d891ece00e98b3f74-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a538c2607b3e458d891ece00e98b3f74-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a538c2607b3e458d891ece00e98b3f74-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a538c2607b3e458d891ece00e98b3f74-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a538c2607b3e458d891ece00e98b3f74-0-3\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a538c2607b3e458d891ece00e98b3f74-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# sentence = \"The objective of the assignment is to learn how to work with dependency graphs by defining functions.\"\n",
    "# sentence = \"Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.\"\n",
    "# sentence = \"bright red apples on the tree\"\n",
    "# sentence = \"Autonomous cars shift insurance liability toward manufacturers\"\n",
    "# sentence = \"The teacher gave the class some homework.\"\n",
    "sentence = \"Sue passed Ann the ball.\"\n",
    "# sentence = \"I saw the man.\"\n",
    "# sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "#display the dep graph\n",
    "doc1 = spacy_nlp(sentence)\n",
    "spacy.displacy.render(doc1, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541075b8-7659-41c7-b569-d7967ea50a80",
   "metadata": {},
   "source": [
    "## First point\n",
    "\n",
    "- extract a path of dependency relations from the ROOT to a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token the path will be a list of dependency relations, where first element is ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65071087-69f1-4128-b819-5bf7f448080f",
   "metadata": {},
   "source": [
    "In this point, my idea was to split the problem into two functions:\n",
    "- the first function __pathDep(token)__ return the path from the root to the token as a normal graph visiting using a FIFO queue. The __input__ is a *spaCy token* and the __output__ is a *list* with inside the tuple *(dependecy_of_the_node, text_of_the_node)*, I added the text to have a more clear output.\n",
    "\n",
    "- the second function __printPathDep(sent)__ prints all the paths of the tokens inside the sentence. As __input__ a *string* representing the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224f4007-36e9-41e7-80eb-944bf09307dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ROOT', 'passed'), ('nsubj', 'Sue')]\n",
      "[('ROOT', 'passed')]\n",
      "[('ROOT', 'passed'), ('dative', 'Ann')]\n",
      "[('ROOT', 'passed'), ('dobj', 'ball'), ('det', 'the')]\n",
      "[('ROOT', 'passed'), ('dobj', 'ball')]\n",
      "[('ROOT', 'passed'), ('punct', '.')]\n"
     ]
    }
   ],
   "source": [
    "# visit as a normal graph visiting\n",
    "def pathDep(token):\n",
    "    S = []\n",
    "    path = []\n",
    "    S.append(token)\n",
    "    while len(S) > 0:\n",
    "        node = S.pop(0)\n",
    "        path.append((node.dep_, node.text))\n",
    "        if node.dep_ != \"ROOT\":\n",
    "            S.append(node.head)\n",
    "    return list(reversed(path))\n",
    "\n",
    "def printPathDep(sent):\n",
    "    doc = spacy_nlp(sent)\n",
    "    path = []\n",
    "    for token in doc:\n",
    "        path = pathDep(token)\n",
    "        print(path)\n",
    "\n",
    "printPathDep(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb74d64-d902-4c2a-8b70-e652f0890bf6",
   "metadata": {},
   "source": [
    "## Second point\n",
    "\n",
    "- extract subtree of a dependents given a token\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - for each token in Doc objects you extract a subtree of its dependents as a list (ordered w.r.t. sentence order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cc6f1-ba9b-4d4d-8f1e-ac8b0952c5a2",
   "metadata": {},
   "source": [
    "Also in this point I decided to split the problem in two function, so that they can be used in the other points:\n",
    "- the first function __subTreeDep(token)__ wants a sapCy token as input an return the list representing the subtree of the token (iterating over the token.subtree as in spaCy docs)\n",
    "\n",
    "- the second function __printSubTreeDep(sent)__ receives as input a sentence and print all the subtree of the tokens inside, by iterating over all the tokens. It could be possible to output a list of list containing all the path for each token, but I think that the first function gives the flexibility to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbcc3a4-b3f7-402f-9ba6-ed42be851b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sue]\n",
      "[Sue, passed, Ann, the, ball, .]\n",
      "[Ann]\n",
      "[the]\n",
      "[the, ball]\n",
      "[.]\n"
     ]
    }
   ],
   "source": [
    "def subTreeDep(token):\n",
    "    tree = []\n",
    "    for sub in token.subtree:\n",
    "        tree.append(sub)\n",
    "    return tree\n",
    "\n",
    "def printSubTreeDep(sent):\n",
    "    doc = spacy_nlp(sent)\n",
    "    for token in doc:\n",
    "        path = subTreeDep(token)\n",
    "        print(path)\n",
    "\n",
    "printSubTreeDep(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f953901-c887-40ab-94fa-a6f101bbf61d",
   "metadata": {},
   "source": [
    "## Third point\n",
    "\n",
    "- check if a given list of tokens (segment of a sentence) forms a subtree\n",
    "    - you parse a sentence and get a Doc object of spaCy\n",
    "    - providing as an input ordered list of words from a sentence, you output True/False based on the sequence forming a subtree or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c87d09-c3d6-4db2-af1e-83b4a4117b32",
   "metadata": {},
   "source": [
    "In the third point, the function __chekSubTree(sent, tokenList)__ get as input the *string* of the sentence to parse, and the *list* of tokens to check if they are contained in a subtree of the sentence. This function reuse *subTreeDep* to retrieve the subtree of each token to then compare it with the passed token list. It returns a *Boolean* as __output__.\n",
    "\n",
    "For a quick test I create a list of word from a sentence and then convert it into a sorted list of tokens with the function __createTokenList(string)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809892f6-4e0e-4323-8b41-32f675cec707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ball', 'the']\n",
      "['Ann', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Pre-create a list of word from a sentence\n",
    "def createTokenList(string):\n",
    "    tok = spacy_nlp(string)\n",
    "    lt = []\n",
    "    for t in tok:\n",
    "        lt.append(str(t))\n",
    "    return sorted(lt)\n",
    "\n",
    "tmp1 = \"the ball\"\n",
    "tmp2 = \"Ann the\"\n",
    "listTokens = createTokenList(tmp1)\n",
    "wrongTokens = createTokenList(tmp2)\n",
    "print(listTokens)\n",
    "print(wrongTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea36449-9476-41c1-b968-0768c8108ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if ['ball', 'the'] forms a subtree: True\n",
      "Check if ['Ann', 'the'] forms a subtree: False\n"
     ]
    }
   ],
   "source": [
    "def checkSubTree(sent, tokenlist):\n",
    "    doc = spacy_nlp(sent)\n",
    "    for token in doc:\n",
    "        path = subTreeDep(token)\n",
    "        pathString = sorted([str(t) for t in path])\n",
    "        if pathString == tokenlist:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print(\"Check if {} forms a subtree: {}\".format(listTokens, checkSubTree(sentence, listTokens)))\n",
    "print(\"Check if {} forms a subtree: {}\".format(wrongTokens, checkSubTree(sentence, wrongTokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38adce5-f781-4a40-a3ca-6e655fc30063",
   "metadata": {},
   "source": [
    "## Fourth point\n",
    "\n",
    "- identify head of a span, given its tokens\n",
    "    - input is a sequence of words (not necessarily a sentence)\n",
    "    - output is the head of the span (single word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bf6b0-c6b2-44b9-a649-68914be00265",
   "metadata": {},
   "source": [
    "Here my doubts were if the input of the function can be a standard *string* or a sliced spaCy document for this reason, I develop:\n",
    "\n",
    "- __headSpan(span)__ receive as __input__ a slice of a spaCy document and return the root by accessing directly to the span propriety\n",
    "\n",
    "- __headSpanString(span)__ receive as __input__ a *string* of list of word and then convert it do a spaCy document for the computing of the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009b3347-a8f9-4627-9365-41a39164a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span: insurance liability toward\n",
      "Head of span: liability\n"
     ]
    }
   ],
   "source": [
    "doc = spacy_nlp(\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "def headSpan(span):\n",
    "    return span.root.text\n",
    "\n",
    "span = doc[3:6]\n",
    "print(\"Span: {}\".format(span))\n",
    "print(\"Head of span: {}\".format(headSpan(span)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6b5e00-e952-4760-8053-7698b551a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of span: liability\n"
     ]
    }
   ],
   "source": [
    "def headSpanString(span):\n",
    "    doc = spacy_nlp(span)\n",
    "    return doc[0:len(doc)].root.text\n",
    "\n",
    "print(\"Head of span: {}\".format(headSpanString(\"insurance liability toward\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed8952-36f7-44b0-9387-e29657d9ae8d",
   "metadata": {},
   "source": [
    "## Fifth point\n",
    "\n",
    "- extract sentence subject, direct object and indirect object spans\n",
    "    - input is a sentence, you parse it and get a Doc object of spaCy\n",
    "    - output is lists of words that form a span (not a single word) for subject, direct object, and indirect object (if present of course, otherwise empty)\n",
    "        - dict of lists, is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd3ff8-50c0-4ba4-abe0-28076d6fac05",
   "metadata": {},
   "source": [
    "This function __extractDep(sent)__ receive in input a *string* of the sentence, convert it as a spaCy doc and returns a *dictionary* containing all the span object for the *subject*, *indirect object* and *direct object* by iterating in its subtree. After iterating the subtree, I decided to convert it into a span object and save it in the dictionary.\n",
    "During some test and looking at the dependency graph, the best way to \"detect\" the indirect object was to use the word *dative* instead of *iobj*. I have not found any documentation about that on spaCy *iobj*, but only for *dative* in [spacy doc](https://spacy.io/models/en). For example, for the sentence \"Sue passed Ann the ball.\", the indirect object Ann is detected by the dative keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75571289-be44-42e6-a53e-70d2f5e3b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nsubj': Sue, 'iobj': Ann, 'dobj': the ball}\n"
     ]
    }
   ],
   "source": [
    "def extractDep(sent):\n",
    "    doc = spacy_nlp(sent)\n",
    "    dic = {}\n",
    "    dic[\"nsubj\"] = None\n",
    "    dic[\"iobj\"] = None\n",
    "    dic[\"dobj\"] = None\n",
    "    s = []\n",
    "    i = []\n",
    "    do = []\n",
    "    \n",
    "    for token in doc:\n",
    "        \n",
    "        if token.dep_ == \"nsubj\":\n",
    "            for d in token.subtree:\n",
    "                    s.append(d.i)\n",
    "            span = doc[s[0]:s[len(s)-1]+1]\n",
    "            dic[\"nsubj\"] = span\n",
    "            \n",
    "        if token.dep_ == \"dative\":\n",
    "            for d in token.subtree:\n",
    "                    i.append(d.i)\n",
    "            span = doc[i[0]:i[len(i)-1]+1]\n",
    "            dic[\"iobj\"] = span\n",
    "            \n",
    "        if token.dep_ == \"dobj\":\n",
    "            for d in token.subtree:\n",
    "                    do.append(d.i)\n",
    "            span = doc[do[0]:do[len(do)-1]+1]\n",
    "            dic[\"dobj\"] = span\n",
    "            \n",
    "    return dic\n",
    "\n",
    "print(extractDep(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "native39",
   "language": "python",
   "name": "native39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
